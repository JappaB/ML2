{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a10081f57b90a368eb8daf62e3ba00e",
     "grade": false,
     "grade_id": "cell-02487845739eb4fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Lab 3: Expectation Maximization and Variational Autoencoder\n",
    "\n",
    "### Machine Learning 2 (2017/2018)\n",
    "\n",
    "* The lab exercises should be made in groups of two or three people.\n",
    "* The deadline is Friday, 01.06.\n",
    "* Assignment should be submitted through BlackBoard! Make sure to include your and your teammates' names with the submission.\n",
    "* Attach the .IPYNB (IPython Notebook) file containing your code and answers. Naming of the file should be \"studentid1\\_studentid2\\_lab#\", for example, the attached file should be \"12345\\_12346\\_lab1.ipynb\". Only use underscores (\"\\_\") to connect ids, otherwise the files cannot be parsed.\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in an IPython Notebook: http://ipython.org/notebook.html. If you have problems, please ask.\n",
    "* Use __one cell__ for code and markdown answers only!\n",
    "    * Put all code in the cell with the ```# YOUR CODE HERE``` comment and overwrite the ```raise NotImplementedError()``` line.\n",
    "    * For theoretical questions, put your solution using LaTeX style formatting in the YOUR ANSWER HERE cell.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Large parts of you notebook will be graded automatically. Therefore it is important that your notebook can be run completely without errors and within a reasonable time limit. To test your notebook before submission, select Kernel -> Restart \\& Run All.\n",
    "$\\newcommand{\\bx}{\\mathbf{x}} \\newcommand{\\bpi}{\\mathbf{\\pi}} \\newcommand{\\bmu}{\\mathbf{\\mu}} \\newcommand{\\bX}{\\mathbf{X}} \\newcommand{\\bZ}{\\mathbf{Z}} \\newcommand{\\bz}{\\mathbf{z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e4e05229ee79b55d6589e1ea8de68f32",
     "grade": false,
     "grade_id": "cell-a0a6fdb7ca694bee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Installing PyTorch\n",
    "\n",
    "In this lab we will use PyTorch. PyTorch is an open source deep learning framework primarily developed by Facebook's artificial-intelligence research group. In order to install PyTorch in your conda environment go to https://pytorch.org and select your operating system, conda, Python 3.6, no cuda. Copy the text from the \"Run this command:\" box. Now open a terminal and activate your 'ml2labs' conda environment. Paste the text and run. After the installation is done you should restart Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9c3d77f550b5fd93b34fd18825c47f0",
     "grade": false,
     "grade_id": "cell-746cac8d9a21943b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### MNIST data\n",
    "\n",
    "In this Lab we will use several methods for unsupervised learning on the MNIST dataset of written digits. The dataset contains digital images of handwritten numbers $0$ through $9$. Each image has 28x28 pixels that each take 256 values in a range from white ($= 0$) to  black ($=1$). The labels belonging to the images are also included. \n",
    "Fortunately, PyTorch comes with a MNIST data loader. The first time you run the box below it will download the MNIST data set. That can take a couple of minutes.\n",
    "The main data types in PyTorch are tensors. For Part 1, we will convert those tensors to numpy arrays. In Part 2, we will use the torch module to directly work with PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fbc152afa1255331d7b88bf00b7156c",
     "grade": false,
     "grade_id": "cell-7c995be0fda080c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "train_labels = train_dataset.train_labels.numpy()\n",
    "train_data = train_dataset.train_data.numpy()\n",
    "# For EM we will use flattened data\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fc852f9bfb0bab10d4c23eada309e89",
     "grade": false,
     "grade_id": "cell-8b4a44df532b1867",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Expectation Maximization\n",
    "We will use the Expectation Maximization (EM) algorithm for the recognition of handwritten digits in the MNIST dataset. The images are modelled as a Bernoulli mixture model (see Bishop $\\S9.3.3$):\n",
    "$$\n",
    "p(\\bx|\\bmu, \\bpi) = \\sum_{k=1}^K  \\pi_k \\prod_{i=1}^D \\mu_{ki}^{x_i}(1-\\mu_{ki})^{(1-x_i)}\n",
    "$$\n",
    "where $x_i$ is the value of pixel $i$ in an image, $\\mu_{ki}$ represents the probability that pixel $i$ in class $k$ is black, and $\\{\\pi_1, \\ldots, \\pi_K\\}$ are the mixing coefficients of classes in the data. We want to use this data set to classify new images of handwritten numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54064637b7e7cf938c0f778d748a226a",
     "grade": false,
     "grade_id": "cell-af03fef663aa85b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Binary data (5 points)\n",
    "As we like to apply our Bernoulli mixture model, write a function `binarize` to convert the (flattened) MNIST data to binary images, where each pixel $x_i \\in \\{0,1\\}$, by thresholding at an appropriate level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe8607a4d734f7f26ef1ee1e54b33471",
     "grade": false,
     "grade_id": "cell-ec4365531ca57ef3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def binarize(X):\n",
    "    return np.array(X > 128, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "231b2c9f29bc5c536c60cef4d74793a1",
     "grade": true,
     "grade_id": "cell-2f16f57cb68a83b3",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test test test!\n",
    "bin_train_data = binarize(train_data)\n",
    "assert bin_train_data.dtype == np.float\n",
    "assert bin_train_data.shape == train_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a0a39404cc2f67078b399ee34653a3ac",
     "grade": false,
     "grade_id": "cell-462e747685e8670f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Sample a few images of digits $2$, $3$ and $4$; and show both the original and the binarized image together with their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3f3c981f0fda5ba3bdfcefb9144305c7",
     "grade": true,
     "grade_id": "cell-784c6bd177a9aa42",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "twos = np.argwhere(train_labels == 2)\n",
    "threes = np.argwhere(train_labels == 3)\n",
    "fours = np.argwhere(train_labels == 4)\n",
    "sample = np.concatenate((twos[:3], threes[:3], fours[:3]))\n",
    "\n",
    "for image_idx in sample:\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    axes[0].imshow(train_data[image_idx].reshape(28, -1))\n",
    "    axes[0].set_title(\"original, label:\"+ str(train_labels[image_idx][0]))\n",
    "    axes[1].imshow(bin_train_data[image_idx].reshape(28, -1))\n",
    "    axes[1].set_title(\"binarized, label:\"+ str(train_labels[image_idx][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4b9da574d24193df76e96ed8ca62c7b0",
     "grade": false,
     "grade_id": "cell-56b33654497d4052",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Implementation (40 points)\n",
    "You are going to write a function ```EM(X, K, max_iter)``` that implements the EM algorithm on the Bernoulli mixture model. \n",
    "\n",
    "The only parameters the function has are:\n",
    "* ```X``` :: (NxD) array of input training images\n",
    "* ```K``` :: size of the latent space\n",
    "* ```max_iter``` :: maximum number of iterations, i.e. one E-step and one M-step\n",
    "\n",
    "You are free to specify your return statement.\n",
    "\n",
    "Make sure you use a sensible way of terminating the iteration process early to prevent unnecessarily running through all epochs. Vectorize computations using ```numpy``` as  much as possible.\n",
    "\n",
    "You should implement the `E_step(X, mu, pi)` and `M_step(X, gamma)` separately in the functions defined below. These you can then use in your function `EM(X, K, max_iter)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "316c9131692747c363b5db8e9091d362",
     "grade": false,
     "grade_id": "cell-882b13c117a73cc4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "def E_step(X, mu, pi):\n",
    "\n",
    "    stabilizer = 1e-6\n",
    "    \n",
    "    #Bishop 9.56\n",
    "    enumerator = X @ np.log(mu+stabilizer).T + (1.0-X) @ np.log(1.0-mu.T+stabilizer) + np.log(pi)\n",
    "#     enumerator = np.dot(X, np.log(mu+stabilizer).T) + np.dot((1.0-X), np.log(1.0-mu.T+stabilizer)) + np.log(pi)\n",
    "    denominator = logsumexp(enumerator, axis=1, keepdims=True)\n",
    "    gamma = np.exp(enumerator - denominator)\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1418f4014e98024fc97446ce27766c1d",
     "grade": true,
     "grade_id": "cell-f7c7dd52d82e2498",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's test on 5 datapoints\n",
    "n_test = 5\n",
    "X_test = bin_train_data[:n_test]\n",
    "D_test, K_test = X_test.shape[1], 10\n",
    "\n",
    "np.random.seed(2018)\n",
    "mu_test = np.random.uniform(low=.25, high=.75, size=(K_test,D_test))\n",
    "pi_test = np.ones(K_test) / K_test\n",
    "\n",
    "gamma_test = E_step(X_test, mu_test, pi_test)\n",
    "assert gamma_test.shape == (n_test, K_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2c426a613653174795cd9c8327ab6e20",
     "grade": false,
     "grade_id": "cell-f1b11b8765bd1ef6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "    #keep dims to be able to divide the whole matrix at once for Pi\n",
    "    Nk_vec = gamma.sum(axis=0, keepdims=True) #gamma dims = (nxk), Nk dims= (1xk)\n",
    "    \n",
    "    # EDIT: N afleiden van data ipv in argument\n",
    "    N, D = X.shape\n",
    "    _, K = gamma.shape\n",
    "    \n",
    "    # Our interpretation of 9.58:\n",
    "#     mu = np.zeros((K, D))\n",
    "#     for k in range(K):\n",
    "#         mu[k, :] = gamma[:, k] @ X\n",
    "#     mu = mu / Nk_vec.T\n",
    "    \n",
    "    # Working implementation of 9.58\n",
    "    mu = gamma.T @ X\n",
    "    mu = mu / Nk_vec.T\n",
    "    \n",
    "    pi = np.squeeze(Nk_vec/N)\n",
    "        \n",
    "    return mu, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f60d48b8b22063cef560b42944a0aa4",
     "grade": true,
     "grade_id": "cell-6e7c751b30acfd45",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Oh, let's test again\n",
    "mu_test, pi_test = M_step(X_test, gamma_test)\n",
    "\n",
    "assert mu_test.shape == (K_test,D_test)\n",
    "assert pi_test.shape == (K_test, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_x_mu(X, MU):\n",
    "    '''Log and matrix version of bishop 9.48'''\n",
    "    \n",
    "    # X = [N, D]\n",
    "    # MU = [K, D]\n",
    "    # return [N, K]\n",
    "    \n",
    "    stabilizer = 1e-3\n",
    "    return X @ np.log(MU.T + stabilizer) + (1.0-X) @ np.log(1 - MU.T + stabilizer)\n",
    "\n",
    "\n",
    "def log_likelihood(gamma, pi, X, mu):\n",
    "    \n",
    "    # [1, K]\n",
    "    log_pi = np.log(pi + 1e-10).reshape(1, -1)\n",
    "    \n",
    "#     print(\"log pi\", log_pi)\n",
    "    \n",
    "    # [N, K]\n",
    "    weighted_log_probs = log_pi + log_x_mu(X, mu)\n",
    "    \n",
    "#     print(\"log x mu\", log_x_mu(X, mu))\n",
    "    \n",
    "    # Element wise multiplication between gamma and weighted\n",
    "    # log-probabilities and then summed over N and K\n",
    "    result = np.sum(gamma * weighted_log_probs)\n",
    "    \n",
    "#     print(\"gamma * weighted\", gamma * weighted_log_probs)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "acfec6384b058cb0ce1932006fbfebc4",
     "grade": true,
     "grade_id": "cell-d6c4368246dee7e6",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def EM(X, K, max_iter, mu=None, pi=None):\n",
    "    \n",
    "    # 'Calculate' N and D\n",
    "    N,D = X.shape\n",
    "    \n",
    "    if not np.any(mu) or not np.any(pi):\n",
    "        # Init\n",
    "        pi = np.ones(K)/K\n",
    "        mu = np.random.rand(K,D)\n",
    "    else:\n",
    "        assert K == mu.shape[0]\n",
    "        \n",
    "    best_log_likelihood = -inf\n",
    "    epsilon = 1e-6 # change in likelihood must be bigger than epsilon\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print('itaration: ', i, '/', max_iter)\n",
    "        \n",
    "        #perform E-step\n",
    "        gamma = E_step(X,mu,pi)        \n",
    "        \n",
    "        #perform M-step\n",
    "        mu,pi = M_step(X, gamma)\n",
    "        \n",
    "#         print(\"mu\", mu)\n",
    "#         print(\"pi\", pi)\n",
    "#         print(\"gamma\", gamma)\n",
    "#         print(\"log-like\", log_likelihood(gamma, pi, X, mu))\n",
    "                \n",
    "#         print(\"M-step mu and pi\", (mu, pi))\n",
    "        \n",
    "        log_like = log_likelihood(gamma, pi, X, mu)\n",
    "        delta = log_like - best_log_likelihood\n",
    "        \n",
    "#         print('log-like: ', log_like)\n",
    "#         print('best log like: ',best_log_likelihood)\n",
    "        # Keep track of log likelihood\n",
    "        log_like = log_likelihood(gamma, pi, X, mu)\n",
    "        delta = log_like - best_log_likelihood    \n",
    "        if delta > 0:\n",
    "            best_log_likelihood = log_like\n",
    "            \n",
    "            # Stop on convergence\n",
    "            if delta < epsilon:\n",
    "                print(\"Converged\")\n",
    "                break\n",
    "            \n",
    "    \n",
    "    return mu, gamma, best_log_likelihood, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itaration:  0 / 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-405.02174941362318"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, gamma, log_like, pi = EM(X_test, 5, 5)\n",
    "log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b4fc12faa0da660f7a4d9cc7deb41b25",
     "grade": false,
     "grade_id": "cell-e1077ed3b83489be",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Three digits experiment (10 points)\n",
    "In analogue with Bishop $\\S9.3.3$, sample a training set consisting of only __binary__ images of written digits $2$, $3$, and $4$. Run your EM algorithm and show the reconstructed digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bdbce0fad0ed151063d4c489ce999e3e",
     "grade": true,
     "grade_id": "cell-477155d0264d7259",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itaration:  0 / 200\n",
      "itaration:  20 / 200\n",
      "itaration:  40 / 200\n",
      "itaration:  60 / 200\n",
      "itaration:  80 / 200\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "# Initialize seed so EM converges to the same thing everytime\n",
    "# This is useful to be able to make a mapping between the cluster centers and the predicted label\n",
    "# (once, and not everytime)\n",
    "random.seed(2018)\n",
    "\n",
    "\n",
    "twos = np.argwhere(train_labels == 2)\n",
    "threes = np.argwhere(train_labels == 3)\n",
    "fours = np.argwhere(train_labels == 4)\n",
    "labels = [2,3,4]\n",
    "samples_per_class = 1000\n",
    "sample_indices = np.concatenate((twos[:samples_per_class], threes[:samples_per_class], fours[:samples_per_class]))\n",
    "samples = np.squeeze(bin_train_data[sample_indices])\n",
    "sample_labels = np.squeeze(train_labels[sample_indices])\n",
    "samples.shape\n",
    "# X_test.shape\n",
    "mu, gamma, best_log_likelihood, pi = EM(samples, 3, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixing coefficients:  [ 0.337  0.306  0.356]\n",
      "True mixing coefficients:  [ 0.333  0.333  0.333]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15364a22e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reconstruction_visualization(mu, pi, samples_per_class, samples):\n",
    "    plt.figure()\n",
    "    K = pi.shape[0]\n",
    "    \n",
    "    for cluster_center in range(K):\n",
    "\n",
    "        plt.subplot(1, K,cluster_center+1)\n",
    "        plt.imshow(mu[cluster_center].reshape(28, -1))\n",
    "    plt.suptitle(\"center means (mu):\")\n",
    "\n",
    "    print(\"Mixing coefficients: \", np.around(pi, decimals=3))\n",
    "    true_mixing = np.ones(3)*samples_per_class/samples.shape[0]\n",
    "    print(\"True mixing coefficients: \",np.around(true_mixing, decimals=3))\n",
    "\n",
    "reconstruction_visualization(mu, pi, samples_per_class, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "485543f4893938d2a9dc1c17d8221cbc",
     "grade": false,
     "grade_id": "cell-88c9664f995b1909",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Can you identify which element in the latent space corresponds to which digit? What are the identified mixing coefficients for digits $2$, $3$ and $4$, and how do these compare to the true ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae7b5acea6089e2590059f90b0d0a0be",
     "grade": true,
     "grade_id": "cell-3680ae2159c48193",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "#### Answer\n",
    "\n",
    "The elements correspond to 3,2,4 from left to right (given that the random seed is set at 2018). The mixing coefficients and the true mixing coefficients are depicted above the plot. The mixing coefficients don't differ too much from the true ones, the EM algorithm thus did a fairly good job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98e04feb59a36867367b3027df9e226d",
     "grade": false,
     "grade_id": "cell-0891dda1c3e80e9a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.4 Experiments (20 points)\n",
    "Perform the follow-up experiments listed below using your implementation of the EM algorithm. For each of these, describe/comment on the obtained results and give an explanation. You may still use your dataset with only digits 2, 3 and 4 as otherwise computations can take very long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "439067186fa3ef1d7261a9bcf5a84ea6",
     "grade": false,
     "grade_id": "cell-06fe1b1355689928",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.1 Size of the latent space (5 points)\n",
    "Run EM with $K$ larger or smaller than the true number of classes. Describe your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "791512aeadd30c4b586b966ca10e6fad",
     "grade": true,
     "grade_id": "cell-6c9057f2546b7215",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itaration:  0 / 200\n",
      "itaration:  20 / 200\n",
      "itaration:  40 / 200\n",
      "itaration:  60 / 200\n",
      "itaration:  80 / 200\n",
      "itaration:  100 / 200\n",
      "itaration:  120 / 200\n",
      "itaration:  140 / 200\n",
      "itaration:  160 / 200\n",
      "itaration:  180 / 200\n"
     ]
    }
   ],
   "source": [
    "random.seed(2018)\n",
    "# K smaller than the true number of classes\n",
    "mu, gamma, best_log_likelihood, pi = EM(samples, 2, 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixing coefficients:  [ 0.387  0.613]\n",
      "True mixing coefficients:  [ 0.333  0.333  0.333]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1535dd49b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruction_visualization(mu, pi, samples_per_class,samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itaration:  0 / 200\n",
      "itaration:  20 / 200\n",
      "itaration:  40 / 200\n",
      "itaration:  60 / 200\n",
      "itaration:  80 / 200\n",
      "itaration:  100 / 200\n",
      "itaration:  120 / 200\n",
      "itaration:  140 / 200\n",
      "itaration:  160 / 200\n",
      "itaration:  180 / 200\n"
     ]
    }
   ],
   "source": [
    "random.seed(2018)\n",
    "# K bigger than the true number of classes\n",
    "mu, gamma, best_log_likelihood, pi = EM(samples, 5, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixing coefficients:  [ 0.18   0.186  0.347  0.147  0.14 ]\n",
      "True mixing coefficients:  [ 0.333  0.333  0.333]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15368a2128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruction_visualization(mu, pi, samples_per_class,samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e12e40c2d2165e3bb500b5504128910d",
     "grade": true,
     "grade_id": "cell-f01c37653160244b",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "## Answer\n",
    "\n",
    "With a K bigger than the true number of classes some mu's/centers depict the same digit. These are potentially the centers of sub-clusters containing different styles of one digit.\n",
    "\n",
    "With a K smaller than the true number of classes, the reconstructed digits are more blurred. This is because in this case perfect assignment is impossible and at least one of the means is the center of a cluster containing multiple digits. In the example above it looks lik the datapoints containing 2's have been divided accros the means for the other two clusters. From the learned mixing coefficients it is seems that most of the 2's have been assigned to the cluster with 3's.\n",
    "\n",
    "NB: The answer above is based on results obained using the random seed 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b306681523a2e35eea310ac10bb68999",
     "grade": false,
     "grade_id": "cell-cf478d67239b7f2e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.2 Identify misclassifications (10 points)\n",
    "How can you use the data labels to assign a label to each of the clusters/latent variables? Use this to identify images that are 'misclassified' and try to understand why they are. Report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, gamma, best_log_likelihood, pi = EM(samples, 3, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_visualization(mu, pi, samples_per_class,samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "000c11bd8756a4e24296c7c55d3ee17e",
     "grade": true,
     "grade_id": "cell-daa1a492fbba5c7e",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def misslassification_experiment(N ,plotting = False):\n",
    "    random.seed(2018)\n",
    "    mapping = {0:3, 1:2, 2:4}\n",
    "    misclassification_counter = 0\n",
    "    predicted_labels = [0,0,0]\n",
    "    while misclassification_counter < N:\n",
    "        image_index = np.random.choice(len(samples)) \n",
    "\n",
    "        assigned_k = np.argmax(gamma[image_index,:])\n",
    "        predicted_label = mapping[assigned_k]\n",
    "        true_label = sample_labels[image_index]\n",
    "        np.delete(samples, image_index)\n",
    "\n",
    "\n",
    "        if (predicted_label != true_label):\n",
    "\n",
    "            # to distinguish which label has been mispredicted more often\n",
    "            if predicted_label == 2:\n",
    "                # use mapping of seed(2018)\n",
    "                predicted_labels[1]+=1\n",
    "            if predicted_label == 3:\n",
    "                # use mapping of seed(2018)\n",
    "                predicted_labels[0]+=1\n",
    "            if predicted_label == 4:\n",
    "                # use mapping of seed(2018)\n",
    "                predicted_labels[2]+=1\n",
    "\n",
    "            misclassification_counter +=1\n",
    "\n",
    "            if plotting == True:\n",
    "        #         print(\"True label: \"+str(true_label)+\"\\t predicted label: \"+str(predicted_label))\n",
    "                plt.figure()\n",
    "                plt.imshow(samples[image_index].reshape(28, -1))\n",
    "                plt.title(str(misclassification_counter)+\") True label: \"+str(true_label)+\" predicted label: \"+str(predicted_label))\n",
    "    \n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = misslassification_experiment(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "baf43434481c13d76ad51e3ba07e2bf5",
     "grade": true,
     "grade_id": "cell-329245c02df7850d",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "640bc57a2d08c3becf534bb5e4b35971",
     "grade": false,
     "grade_id": "cell-67ce1222e8a7837b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.3 Initialize with true values (5 points)\n",
    "Initialize the three classes with the true values of the parameters and see what happens. Report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a48f788e286458ef0f776865a3bcd58b",
     "grade": true,
     "grade_id": "cell-aa5d6b9f941d985d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixing coefficients:  [ 0.333  0.333  0.333]\n",
      "True mixing coefficients:  [ 0.333  0.333  0.333]\n",
      "itaration:  0 / 200\n",
      "itaration:  20 / 200\n",
      "itaration:  40 / 200\n",
      "itaration:  60 / 200\n",
      "itaration:  80 / 200\n",
      "itaration:  100 / 200\n",
      "itaration:  120 / 200\n",
      "itaration:  140 / 200\n",
      "itaration:  160 / 200\n",
      "itaration:  180 / 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1536ea4eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed again\n",
    "# random.seed()\n",
    "\n",
    "K = 3\n",
    "mu_true = np.zeros((K, 784))\n",
    "mu_true[0, :] = np.mean(samples[sample_labels == 2], axis=0)\n",
    "mu_true[1, :] = np.mean(samples[sample_labels == 3], axis=0)\n",
    "mu_true[2, :] = np.mean(samples[sample_labels == 4], axis=0)\n",
    "pi_true = np.ones(K)*(samples_per_class/samples.shape[0])\n",
    "\n",
    "print(\"Initalize on true parameters:\")\n",
    "reconstruction_visualization(mu_true, pi_true, samples_per_class, samples)\n",
    "mu, gamma, best_log_likelihood, pi = EM(samples, 3, 200, mu_true, pi_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixing coefficients:  [ 0.307  0.337  0.356]\n",
      "True mixing coefficients:  [ 0.333  0.333  0.333]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1552519780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruction_visualization(mu, 3, samples_per_class, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1dc4adf3081f3bec93f94c3b12b87db9",
     "grade": true,
     "grade_id": "cell-981e44f35a3764b0",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "One might expect that initalizing EM with the true parameters would lead to immediate convergence. The experiment, however, shows that this is not the case. The algorithm adjusts the paramters away from the true values. This can be explained by the fact that the EM-algorithm uses a log bernoulli objective (ie. minimize the pixel-to-pixel difference of the mean and a datapoint). Therefore any variance in the handwriting can cause a digit to be interpreted as for example a 2 instead of a 3. So the likelihood can be increased by increasing the responsibility of the cluster of 2's for that datapoint, shifting away from the true parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd613f41e5d2b7d22b0d5b1e7644a48a",
     "grade": false,
     "grade_id": "cell-19bfd7cf4017ed84",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Variational Auto-Encoder\n",
    "\n",
    "A Variational Auto-Encoder (VAE) is a probabilistic model $p(\\bx, \\bz)$ over observed variables $\\bx$ and latent variables and/or parameters $\\bz$. Here we distinguish the decoder part, $p(\\bx | \\bz) p(\\bz)$ and an encoder part $p(\\bz | \\bx)$ that are both specified with a neural network. A lower bound on the log marginal likelihood $\\log p(\\bx)$ can be obtained by approximately inferring the latent variables z from the observed data x using an encoder distribution $q(\\bz| \\bx)$ that is also specified as a neural network. This lower bound is then optimized to fit the model to the data. \n",
    "\n",
    "The model was introduced by Diederik Kingma (during his PhD at the UVA) and Max Welling in 2013, https://arxiv.org/abs/1312.6114. \n",
    "\n",
    "Since it is such an important model there are plenty of well written tutorials that should help you with the assignment. E.g: https://jaan.io/what-is-variational-autoencoder-vae-tutorial/.\n",
    "\n",
    "In the following, we will make heavily use of the torch module, https://pytorch.org/docs/stable/index.html. Most of the time replacing `np.` with `torch.` will do the trick, e.g. `np.sum` becomes `torch.sum` and `np.log` becomes `torch.log`. In addition, we will use `torch.FloatTensor()` as an equivalent to `np.array()`. In order to train our VAE efficiently we will make use of batching. The number of data points in a batch will become the first dimension of our data tensor, e.g. A batch of 128 MNIST images has the dimensions [128, 1, 28, 28]. To check check the dimensions of a tensor you can call `.size()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92bd337f41c3f94777f47376c7149ca7",
     "grade": false,
     "grade_id": "cell-bcbe35b20c1007d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Loss function\n",
    "The objective function (variational lower bound), that we will use to train the VAE, consists of two terms: a log Bernoulli loss (reconstruction loss) and a KullbackLeibler divergence. We implement the two terms separately and combine them in the end.\n",
    "As seen in Part 1: Expectation Maximization, we can use a multivariate Bernoulli distribution to model the likelihood $p(\\bx | \\bz)$ of black and white images. Formally, the variational lower bound is maximized but in PyTorch we are always minimizing therefore we need to calculate the negative log Bernoulli loss and KullbackLeibler divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3fb5f70b132e1233983ef89d19998374",
     "grade": false,
     "grade_id": "cell-389d81024af846e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1.1 Negative Log Bernoulli loss (5 points)\n",
    "The negative log Bernoulli loss is defined as,\n",
    "\n",
    "\\begin{align}\n",
    "loss = - (\\sum_i^D \\bx_i \\log \\hat{\\bx_i} + (1  \\bx_i) \\log(1  \\hat{\\bx_i})).\n",
    "\\end{align}\n",
    "\n",
    "Write a function `log_bernoulli_loss` that takes a D dimensional vector `x`, its reconstruction `x_hat` and returns the negative log Bernoulli loss. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "952435ca03f47ab67a7e88b8306fc9a0",
     "grade": false,
     "grade_id": "cell-1d504606d6f99145",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def log_bernoulli_loss(x_hat, x):\n",
    "    \n",
    "    stabilizer = 0\n",
    "    loss = x * torch.log(x_hat + stabilizer) + (1 - x) * torch.log(1 - x_hat + stabilizer)\n",
    "    loss = -torch.sum(loss)\n",
    "#     loss = F.binary_cross_entropy(x_hat, x, size_average=False)    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd2a490aa694507bd032e86d77fc0087",
     "grade": true,
     "grade_id": "cell-9666dad0b2a9f483",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test test test\n",
    "x_test = torch.FloatTensor([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 0.9, 0.9, 0.9]])\n",
    "x_hat_test = torch.FloatTensor([[0.11, 0.22, 0.33, 0.44], [0.55, 0.66, 0.77, 0.88], [0.99, 0.99, 0.99, 0.99]])\n",
    "\n",
    "assert log_bernoulli_loss(x_hat_test, x_test) > 0.0\n",
    "assert log_bernoulli_loss(x_hat_test, x_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b75b7a531ecc87bce57925c4da464ee",
     "grade": false,
     "grade_id": "cell-b3a7c02dee7aa505",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1.2 Negative KullbackLeibler divergence (10 Points)\n",
    "The variational lower bound (the objective to be maximized) contains a KL term $D_{KL}(q(\\bz)||p(\\bz))$ that can often be calculated analytically. In the VAE we assume $q = N(\\bz, \\mu, \\sigma^2I)$ and $p = N(\\bz, 0, I)$. Solve analytically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d01a7e7fe2dcf5f1c5fb955b85c8a04a",
     "grade": true,
     "grade_id": "cell-4cab10fd1a636858",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "% TODO: Derivation\n",
    "\n",
    "$$ -KL(q||p) = \\frac{1}{2} * \\sum_{j=1}^J (1 + log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2)$$\n",
    "\n",
    "$$KL(p,q)=log21+21+(12)222212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "328115c94a66e8aba0a62896e647c3ba",
     "grade": false,
     "grade_id": "cell-c49899cbf2a49362",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Write a function `KL_loss` that takes two J dimensional vectors `mu` and `logvar` and returns the negative KullbackLeibler divergence. Where `logvar` is $\\log(\\sigma^2)$. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33b14b79372dd0235d67bb66921cd3e0",
     "grade": false,
     "grade_id": "cell-125b41878005206b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def KL_loss(mu, logvar):\n",
    "    \n",
    "    loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())   \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf72e196d2b60827e8e940681ac50a07",
     "grade": true,
     "grade_id": "cell-ba714bbe270a3f39",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test test test\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "assert KL_loss(mu_test, logvar_test) > 0.0\n",
    "assert KL_loss(mu_test, logvar_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65335a588baac26bc48dd6c4d275fdca",
     "grade": false,
     "grade_id": "cell-18cb3f8031edec23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1.3 Putting the losses together (5 points)\n",
    "Write a function `loss_function` that takes a D dimensional vector `x`, its reconstruction `x_hat`, two J dimensional vectors `mu` and `logvar` and returns the final loss. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f6ecb5b60b2c8d7b90070ed59320ee70",
     "grade": false,
     "grade_id": "cell-d2d18781683f1302",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(x_hat, x, mu, logvar):\n",
    "    \n",
    "    recon = log_bernoulli_loss(x_hat, x)\n",
    "    kl = KL_loss(mu, logvar)\n",
    "    \n",
    "    loss = recon + kl\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "816e9508408bfcb2c7332b508d505081",
     "grade": true,
     "grade_id": "cell-57747988d29bbb5d",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "x_hat_test = torch.FloatTensor([[0.11, 0.22, 0.33], [0.44, 0.55, 0.66], [0.77, 0.88, 0.99]])\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "assert loss_function(x_hat_test, x_test, mu_test, logvar_test) > 0.0\n",
    "assert loss_function(x_hat_test, x_test, mu_test, logvar_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4506e06ed44a0535140582277a528ba4",
     "grade": false,
     "grade_id": "cell-9e3ba708967fe918",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 The model\n",
    "Below you see a data structure for the VAE. The modell itself consists of two main parts the encoder (images $\\bx$ to latent variables $\\bz$) and the decoder (latent variables $\\bz$ to images $\\bx$). The encoder is using 3 fully-connected layers, whereas the decoder is using fully-connected layers. Right now the data structure is quite empty, step by step will update its functionality. For test purposes we will initialize a VAE for you. After the data structure is completed you will do the hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "31eccf2f6600764e28eb4bc6c5634e49",
     "grade": false,
     "grade_id": "cell-e7d9dafee18f28a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, fc1_dims, fc21_dims, fc22_dims, fc3_dims, fc4_dims):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(*fc1_dims)\n",
    "        self.fc21 = nn.Linear(*fc21_dims)\n",
    "        self.fc22 = nn.Linear(*fc22_dims)\n",
    "        self.fc3 = nn.Linear(*fc3_dims)\n",
    "        self.fc4 = nn.Linear(*fc4_dims)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def decode(self, z):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "VAE_test = VAE(fc1_dims=(784, 4), fc21_dims=(4, 2), fc22_dims=(4, 2), fc3_dims=(2, 4), fc4_dims=(4, 784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a2243397998b4f55c25dfd734f3e7e0",
     "grade": false,
     "grade_id": "cell-c4f9e841b8972a43",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Encoding (10 points)\n",
    "Write a function `encode` that gets a vector `x` with 784 elements (flattened MNIST image) and returns `mu` and `logvar`. Your function should use three fully-connected layers (`self.fc1()`, `self.fc21()`, `self.fc22()`). First, you should use `self.fc1()` to embed `x`. Second, you should use `self.fc21()` and `self.fc22()` on the embedding of `x` to compute `mu` and `logvar` respectively. PyTorch comes with a variety of activation functions, the most common calls are `F.relu()`, `F.sigmoid()`, `F.tanh()`. Make sure that your function works for batches of arbitrary size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "628bcd88c611cf01e70f77854600199b",
     "grade": false,
     "grade_id": "cell-93cb75b98ae76569",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def encode(self, x):\n",
    "    \n",
    "    embed = self.fc1(x)\n",
    "    embed = F.sigmoid(embed)\n",
    "    \n",
    "    mu = self.fc21(embed)\n",
    "    logvar = self.fc22(embed)\n",
    "        \n",
    "    return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "370d930fa9f10f1d3a451f3805c04d88",
     "grade": true,
     "grade_id": "cell-9648960b73337a70",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test, test, test\n",
    "VAE.encode = encode\n",
    "\n",
    "x_test = torch.ones((5,784))\n",
    "mu_test, logvar_test = VAE_test.encode(x_test)\n",
    "\n",
    "assert np.allclose(mu_test.size(), [5, 2])\n",
    "assert np.allclose(logvar_test.size(), [5, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f597cc2b5ef941af282d7162297f865",
     "grade": false,
     "grade_id": "cell-581b4ed1996be868",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Reparameterization (10 points)\n",
    "One of the major question that the VAE is answering, is 'how to take derivatives with respect to the parameters of a stochastic variable?', i.e. if we are given $\\bz$ that is drawn from a distribution $q(\\bz|\\bx)$, and we want to take derivatives. This step is necessary to be able to use gradient-based optimization algorithms like SGD.\n",
    "For some distributions, it is possible to reparameterize samples in a clever way, such that the stochasticity is independent of the parameters. We want our samples to deterministically depend on the parameters of the distribution. For example, in a normally-distributed variable with mean $\\mu$ and standard deviation $\\sigma$, we can sample from it like this:\n",
    "\n",
    "\\begin{align}\n",
    "\\bz = \\mu + \\sigma \\odot \\epsilon,\n",
    "\\end{align}\n",
    "\n",
    "where $\\odot$ is the element-wise multiplication and $\\epsilon$ is sampled from $N(0, I)$.\n",
    "\n",
    "\n",
    "Write a function `reparameterize` that takes two J dimensional vectors `mu` and `logvar`. It should return $\\bz = \\mu + \\sigma \\odot \\epsilon$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6331cb5dd23aaacbcf1a52cfecb1afaa",
     "grade": false,
     "grade_id": "cell-679aea8b2adf7ec4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reparameterize(self, mu, logvar):\n",
    "        \n",
    "        eps = torch.randn_like(mu)\n",
    "        z = mu + torch.sqrt(torch.exp(logvar)) * eps\n",
    "\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38d4e047717ab334b262c8c177f0a420",
     "grade": true,
     "grade_id": "cell-fdd7b27a3d17f84e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test, test, test\n",
    "VAE.reparameterize = reparameterize\n",
    "VAE_test.train()\n",
    "\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "z_test = VAE_test.reparameterize(mu_test, logvar_test)\n",
    "\n",
    "assert np.allclose(z_test.size(), [3, 2])\n",
    "assert z_test[0][0] < 5.0\n",
    "assert z_test[0][0] > -5.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9241ab0eaf8366c37ad57072ce66f095",
     "grade": false,
     "grade_id": "cell-0be851f9f7f0a93e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Decoding (10 points)\n",
    "Write a function `decode` that gets a vector `z` with J elements and returns a vector `x_hat` with 784 elements (flattened MNIST image). Your function should use two fully-connected layers (`self.fc3()`, `self.fc4()`). PyTorch comes with a variety of activation functions, the most common calls are `F.relu()`, `F.sigmoid()`, `F.tanh()`. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e8e833cfd7c54a9b67a38056d5d6cab8",
     "grade": false,
     "grade_id": "cell-bf92bb3878275a41",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decode(self, z):\n",
    "    \n",
    "    x_hat = self.fc3(z)\n",
    "    x_hat = F.relu(x_hat)\n",
    "    x_hat = self.fc4(x_hat)\n",
    "    x_hat = F.sigmoid(x_hat)\n",
    "    \n",
    "    return x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7732293fd7d971fcf255496e8c68638d",
     "grade": true,
     "grade_id": "cell-4abb91cb9e80af5d",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test test test\n",
    "VAE.decode = decode\n",
    "\n",
    "z_test = torch.ones((5,2))\n",
    "x_hat_test = VAE_test.decode(z_test)\n",
    "\n",
    "assert np.allclose(x_hat_test.size(), [5, 784])\n",
    "assert (x_hat_test <= 1).all()\n",
    "assert (x_hat_test >= 0).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e2e113d1f45398b2a1399c336526e755",
     "grade": false,
     "grade_id": "cell-97511fbc4f5b469b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.6 Forward pass (10)\n",
    "To complete the data structure you have to define a forward pass through the VAE. A single forward pass consists of the encoding of an MNIST image $\\bx$ into latent space $\\bz$, the reparameterization of $\\bz$ and the decoding of $\\bz$ into an image $\\bx$.\n",
    "\n",
    "Write a function `forward` that gets a a vector `x` with 784 elements (flattened MNIST image) and returns a vector `x_hat` with 784 elements (flattened MNIST image), `mu` and `logvar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8b7433c4631dd01c07a5fe287e55ae13",
     "grade": false,
     "grade_id": "cell-26bb463b9f98ebd5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = x.view(-1, 784)\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    x_hat = self.decode(z)\n",
    "    return x_hat, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e7e495f40465c162512e9873c360b25",
     "grade": true,
     "grade_id": "cell-347e5fba3d02754b",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test test test \n",
    "VAE.forward = forward\n",
    "\n",
    "x_test = torch.ones((5,784))\n",
    "x_hat_test, mu_test, logvar_test = VAE_test.forward(x_test)\n",
    "\n",
    "assert np.allclose(x_hat_test.size(), [5, 784])\n",
    "assert np.allclose(mu_test.size(), [5, 2])\n",
    "assert np.allclose(logvar_test.size(), [5, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a114a6fd781fb949b887e6a028e07946",
     "grade": false,
     "grade_id": "cell-62c89e4d3b253671",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.7 Training (15)\n",
    "We will now train the VAE using an optimizer called Adam, https://arxiv.org/abs/1412.6980. The code to train a model in PyTorch is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3b6bb965fb48229c63cacda48baea65",
     "grade": false,
     "grade_id": "cell-be75f61b09f3b9b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(epoch, train_loader, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data.view(-1, 784), mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48ca730dbef06a668f4dfdb24888f265",
     "grade": false,
     "grade_id": "cell-da1b063b7de850b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's train. You have to choose the hyperparameters. Make sure your loss is going down in a reasonable amount of epochs (around 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "846430258fb80f50b161135448726520",
     "grade": false,
     "grade_id": "cell-d4d4408d397f6967",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 2\n",
    "hidden_dim = 256\n",
    "fc1_dims = (784,hidden_dim)\n",
    "fc21_dims = (hidden_dim, latent_dim)\n",
    "fc22_dims = (hidden_dim, latent_dim)\n",
    "fc3_dims = (latent_dim, hidden_dim)\n",
    "fc4_dims = (hidden_dim, 784)\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b93390f399b743276bc25e67493344f2",
     "grade": true,
     "grade_id": "cell-ca352d8389c1809a",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains a hidden test, please don't delete it, thx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "20719070ed85964de9722acc3456a515",
     "grade": false,
     "grade_id": "cell-5c77370db7cec9f2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the box below to train the model using the hyperparameters you entered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38306be3638e85812bd5b2a052fcc0a4",
     "grade": false,
     "grade_id": "cell-5712d42de1068398",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "# Load data\n",
    "train_data = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size, shuffle=True, **{})\n",
    "\n",
    "# Init model\n",
    "VAE_MNIST = VAE(fc1_dims=fc1_dims, fc21_dims=fc21_dims, fc22_dims=fc22_dims, fc3_dims=fc3_dims, fc4_dims=fc4_dims)\n",
    "\n",
    "# Init optimizer\n",
    "optimizer = optim.Adam(VAE_MNIST.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, train_loader, VAE_MNIST, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e2f8fcc9384e30cb154cf931f223898b",
     "grade": false,
     "grade_id": "cell-bd07c058c661b9c6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the box below to check if the model you trained above is able to correctly reconstruct images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80d198e03b1287741d761a12e38dcf73",
     "grade": false,
     "grade_id": "cell-df03d717307a6863",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Let's check if the reconstructions make sense\n",
    "# Set model to test mode\n",
    "VAE_MNIST.eval()\n",
    "    \n",
    "# Reconstructed\n",
    "train_data_plot = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "train_loader_plot = torch.utils.data.DataLoader(train_data_plot,\n",
    "                                           batch_size=1, shuffle=False, **{})\n",
    "\n",
    "for batch_idx, (data, _) in enumerate(train_loader_plot):\n",
    "    x_hat, mu, logvar = VAE_MNIST(data)\n",
    "    plt.imshow(x_hat.view(1,28,28).squeeze().data.numpy(), cmap='gray')\n",
    "    plt.title('%i' % train_data.train_labels[batch_idx])\n",
    "    plt.show()\n",
    "    if batch_idx == 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f559122b150f5f1228d6b66b62f462c",
     "grade": false,
     "grade_id": "cell-76649d51fdf133dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.8 Visualize latent space (20 points)\n",
    "Now, implement the auto-encoder now with a 2-dimensional latent space, and train again over the MNIST data. Make a visualization of the learned manifold by using a linearly spaced coordinate grid as input for the latent space, as seen in  https://arxiv.org/abs/1312.6114 Figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c879ffdb0d355349d7144a33d16ca93a",
     "grade": true,
     "grade_id": "cell-4a0af6d08d055bee",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "N = 25\n",
    "rows = np.linspace(-3, 3, N)\n",
    "cols = rows.copy()\n",
    "\n",
    "fig, ax = plt.subplots(N, N, figsize=(14,14))\n",
    "\n",
    "for i_idx, i in enumerate(rows):\n",
    "    for j_idx, j in enumerate(cols):\n",
    "        \n",
    "        # Build tensor t\n",
    "        z = torch.FloatTensor([i, j]).unsqueeze(0)\n",
    "        x = VAE_MNIST.decode(z).data.numpy()\n",
    "        ax[i_idx,j_idx].imshow(x.reshape(28, -1))\n",
    "        ax[i_idx,j_idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b9eb1684d646eea84a25638d184bfbda",
     "grade": false,
     "grade_id": "cell-dc5e1247a1e21009",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.8 Amortized inference (10 points)\n",
    "What is amortized inference? Where in the code of Part 2 is it used? What is the benefit of using it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "364ed922da59070f319d0bdfb0e41d92",
     "grade": true,
     "grade_id": "cell-6f7808a9b0098dbf",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "TODO: http://ruishu.io/2017/11/07/amortized-optimization/\n",
    "\n",
    "Amortized inference is a term used to describe the process of doing inference on multiple related problems concurrently. A Variational Auto-encoder uses amortized inference to solve the sub-problems of optimizing the posterior distribution $p(z|x)$ by learning a function $f$ that maps from x to z. This by-passes the need to optimize the posterior for every data point seperately. And in addition to that, the learned function can be used to predict the latent variables that generated a new observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
